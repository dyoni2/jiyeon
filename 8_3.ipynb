{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNiJhpzHCy+8+lhBF5WDBII",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dyoni2/jiyeon/blob/main/8_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 신경망의 시각화\n",
        "\n",
        "합성곱이 이미지에서 어떤 것을 학습했는지 알아보기 위해 합성을 중의 가중치와 합성곱 신경망의 동작 원리에 대한 통찰력을 높일 수 있음\n",
        "\n",
        "이전 월(주)에서 훈연했던 모일 파라미터가 필요"
      ],
      "metadata": {
        "id": "cfWhCr4zaklZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**가중치 시각화**\n",
        "\n",
        "합성곱 층은 여러 개의 필터를 사용해 이미지에서 특징을 학습함\n",
        "\n",
        "각 필터는 커널이라 부르는 가중치와 절편을 보유 일반적으로 절편은 시각적으로 의미가 없음\n",
        "\n",
        "가중치는 입력 이미지의 2차원 영역에 적용되어 어떤 특징을 크게 두드러지게 표현하는 역할을 함\n",
        "\n",
        "예를 어 둥근 모서리가 있는 영역을 크게 활성화하고 그렇지 않은 영역은 낮은 값을 만듦\n",
        "\n",
        "즉, 이 필터는 곡선 부분의 가중치 값이 높고 그외 부분은 가중치 값이 낮을 것임.\n",
        "\n",
        "그래야만 둥근 모서리가 있는 입력과 곱해져서 큰 출력을 만들기 때문"
      ],
      "metadata": {
        "id": "j8Dxk3R0atZU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "체크포인트파일 불러오기"
      ],
      "metadata": {
        "id": "sHRn2A2jbrcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRK92CN2e0E1",
        "outputId": "0444d8a1-87a6-4676-b86a-62ebdd013b32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "nmH23qpWafSa",
        "outputId": "fc4ad8c2-f9b3-44ec-9411-07362d228def"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-b630b22de820>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/8-2-best-cnn-model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/legacy/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                             raise IOError(\n\u001b[0m\u001b[1;32m    235\u001b[0m                                 \u001b[0;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                             )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at /content/drive/MyDrive/8-2-best-cnn-model.h5"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/drive/MyDrive/8-2-best-cnn-model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "케라스 모델에 추가한 층은 layers에 추가돼있음"
      ],
      "metadata": {
        "id": "uwlUAzy7ftwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "id": "XJ6OPQvrfhZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv = model.layers[0]\n",
        "\n",
        "print(conv.weights[0].shape, conv.weights[1].shape)"
      ],
      "metadata": {
        "id": "eC5t6kvlfoLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "커널의 크기가 (3,3)이고, 합성곱 층에 전달되는 입력의 깊이자 1이므로 실제 커널 크기는 (3,3.1)임\n",
        "\n",
        "필터 개수가 32개 이므로 weights의 첫 번째 원소인 가중치의 크기는 (3,3.1.32)\n",
        "\n",
        "weights의 두 번째 원소는 절편의 개수를 나타내며 각 필터마다 1개의 절편이 있으므로 (32)"
      ],
      "metadata": {
        "id": "SRixH6EKfpMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_weights = conv.weights[0].numpy()\n",
        "\n",
        "print(conv_weights.mean(), conv_weights.std())"
      ],
      "metadata": {
        "id": "_A4pcQcxf2B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**가중치 히스토그램**\n",
        "\n",
        "weights  속성은 텐서플로의 다차원 배열인 Tensor 클래스의 객체임\n",
        "\n",
        "다루기 쉽도록 넘파이 배열로 변환\n",
        "\n",
        "먼저 가중치 배열의 평균과 표준편자를 계산하고 히스토그램으로 값을 확인하자"
      ],
      "metadata": {
        "id": "9k49Kmxyf2fo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_weights = conv.weights[0].numpy()\n",
        "\n",
        "print(conv_weights.mean(), conv_weights.std()), conv_weights.max(), conv_weights.min()"
      ],
      "metadata": {
        "id": "82vw1j0NgGIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.hist(conv_weights.reshape(-1, 1))\n",
        "plt.xlabel('weight')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IkkN8ZY-gUrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "히스토그램을 보면 0을 중심으로 종 모양 분포를 띄고 있음\n",
        "\n",
        "이 가중치는 무엇인가 의미를 학습한 것인가?"
      ],
      "metadata": {
        "id": "WE9-Zo1Tga4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 32개의 필터를 16개씩 두 줄에 출력\n",
        "fig, axs = plt.subplots(2, 16, figsize=(15,2)) # figsize는 각 subplots의 크기가 아닌 전체 그림의 크기\n",
        "\n",
        "for i in range(2):\n",
        "    for j in range(16):\n",
        "        axs[i, j].imshow(conv_weights[:,:,0,i*16 + j], vmin=-0.5, vmax=0.5) # vmin vamx: 색상의 최소값과 최대값을 조정, vmax보다 큰 값은 vmax의, vmin보다 작은 값은 vmin의\n",
        "        axs[i, j].axis('off')\n",
        "# plt.savefig('8-3-hist.png') # 그림 저장\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8Zmi4AO7ghkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결과 그래프를 보면 가중치 값이 무작위로 나열된 것이 아닌 어떤 패턴을 볼 수 있음\n",
        "참고로 밝은 부분의 값이 높음\n",
        "첫 번째 줄의 11번재 필터에서 위쪽의 3픽셀의 값이 높음 즉, 이 가중치는 직선을 만나면 크게 활성화될 것임"
      ],
      "metadata": {
        "id": "XEzC4iIug8jk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 신경망의 가중치는 어떻게 선택될까?"
      ],
      "metadata": {
        "id": "TypqDRdNhQil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련하지 않은 빈 합성곱 신경망을 만들고 분석해보자\n",
        "no_training_model = keras.Sequential()\n",
        "no_training_model.add(keras.layers.Conv2D(32, kernel_size=3, activation='relu', padding='same', input_shape=(28,28,1)))\n",
        "no_training_conv = no_training_model.layers[0]\n",
        "print(no_training_conv.weights[0].shape)"
      ],
      "metadata": {
        "id": "mOeRyaiAhqAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "평균은 이전과 동일하게 0에 가깝지만 표준편차는 이전과 달리 매우 작음\n",
        "\n",
        "또한 최대값과 최소값의 차이도 작음"
      ],
      "metadata": {
        "id": "n6AJpp5UiBh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_training_weights = no_training_conv.weights[0].numpy()\n",
        "\n",
        "print(no_training_weights.mean(), no_training_weights.std())"
      ],
      "metadata": {
        "id": "iz_xueUjh2MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(no_training_weights.reshape(-1, 1))\n",
        "plt.xlabel('weight')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aF6wCf8oh4Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "대부분의 가중치가 -0.15 ~ 0.15 사이에 존재하여 비교적 고른 분포를 보임\n",
        "\n",
        "텐서플로가 신경망의 가중치를 처음 초기화할 때 균등 분포에서 랜덤하게 값을 선택하기 때문"
      ],
      "metadata": {
        "id": "Dnr33r-dh5Sp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체적으로 가중치가 밋밋하게 초기화되어 있음\n",
        "\n",
        "훈련이 끝난 이전 가중치와 비교하면 합성곱 신경망이 패션 MNIST 데이터셋의 분류 정확도를 높이기 위해 유용한 패턴을 학습했다는 것을 알 수 있음"
      ],
      "metadata": {
        "id": "ES02gntciKIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**함수형 API(Application Programming Interface)**\n",
        "\n",
        "케라스 Sequental 클래스: 층을 차례대로 쌓은 모델\n",
        "\n",
        "딥러닝에서는 좀 더 복잡한 모델이 존재 입력이 2개일 수도 있고 출력이 2개일 수도 있음\n",
        "\n",
        "이러한 경우에 함수형 API(functional API)를 사용함\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "함수형 API는 케라스의 Model 클래스를 사용하여 모델을 만듦 예를 들어, 7장에서 만들었던 Dense 층 2개로 이루어진 완전 연결 신경망을 함수형 AP로 구현하면 다음과 같음\n",
        "\n",
        "densel = keras.layers.Dense(100, activation='slgmoid')\n",
        "\n",
        "dense2 = keras.layers.Dense(10, activation='softmax)\n",
        "\n",
        "이 두 코드는 7장과 거의 동일\n",
        "\n",
        "이 객체를 Sequential 클래스 객체의 add0 메서드에 전달할 수 있으나 다음과 같이 함수처럼 호출할 수 있음\n",
        "\n",
        "hidden = dense1(inputs)\n",
        "\n",
        "파이썬의 모든 객체는 호출이 가능함\n",
        "\n",
        "케라스의 증은 객체를 함수처럼 호출했을 때 적절히 동작할 수 있도록 미리 준비해 놓음\n",
        "\n",
        "위 코드는 입력값 inputs를 Dense 층에 통과시킨 후 출력값 hidden을 만들어줌\n",
        "\n",
        "이런 특성이 함수형 API라고 부르게 함\n",
        "\n",
        "두 번째 층은 다음과 같이 호출함.\n",
        "\n",
        "이때 첫 번째 층의 출력을 입력으로 사용함\n",
        "\n",
        "outputs = dense2(hidden)\n",
        "\n",
        "그다음 inputs와 outputs를 Model 클래스로 연결\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "입력에서 출력까지 층을 호출한 결과를 계속 이어주고 Model 클래스에 입력과 최종 출력을 지정\n"
      ],
      "metadata": {
        "id": "bUp11q8UiVY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**inputs이란?**\n",
        "\n",
        "8-2에서 ploy_model() 함수로 모델의 층을 도식화했을 때 InputLayer 클래스가 처음에 나왔음\n",
        "\n",
        "Sequential 클래스는 InputLayer 클래스를 자동으로 추가하고 호출함\n",
        "\n",
        "그러나 Model 클래스에서는 수동으로 만들어서 호출해야 함\n",
        "\n",
        "이 inputs o InputLayer 클래스의 출력값이 되어야 함\n",
        "\n",
        "**Seauential 클래스에서 InoutLaver의 객체는 어디에 저장되는가?**\n",
        "\n",
        "케라스 모델은 leyers 속성 외에 InputLayer 객체를 포함한_Self_tracked_trackables 리스트 속성을 가지고 있음\n",
        "\n",
        "Sequential 클래스 객체의_self_tracked_trackables 속성의 첫 번째 항목이 InputLayer 클래스의 객체임\n",
        "\n",
        "InputLayer클래스는 신경망의 입력층 역할을 함\n",
        "\n",
        "즉 모델의 입력을 첫 번째 은닉층에 전달하는 역할을 수행\n",
        "\n",
        "따라서 InputLayer 객체의 입력과 출력은 동일함\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "inputs을 지정하기 위해 Input0 함수를 입력의 크기를 지정하는 shape 매개변수와 함께 사용\n",
        "\n",
        "inputs = keras.Input(shape=(784, ))\n",
        "\n",
        "마치 체인처럼 입력에서 출력까지 연결하고 마지막에 Model 클래스에 입력과 출력을 지정하여 모델을 만듦\n",
        "\n",
        "이렇게 모델을 만들면 중간에 다양한 형채로 층을 연결할 수 있음"
      ],
      "metadata": {
        "id": "HQCzFjDqi9XT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**특성 맵 시각화를 만드는 데 함수형 API가 필요한 이유?**\n",
        "\n",
        "8-2에서 정의한 model 객체의 층을 순서대로 나열하면 다음과 같음\n",
        "\n",
        "InputLayer -> Conv2D -> MaxPooling2D → Conv2D -> MaxPooling2D -> Flatten -> Dense -> Dropout -> Dense\n",
        "\n",
        "첫 번째 Conv2D의 출력을 알고 싶다면, model 객체의 입력과 Conv2D의 출력을 이용해\n",
        "들고 이를 이용"
      ],
      "metadata": {
        "id": "gEA1defDkwm8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 객체의 predict0 메서드를 호출하면 입력부터 마지막 층까지 모든 계산을 수행한 후 최종 출력을 반환함\n",
        "\n",
        "그러나 필요한 것은 첫 번째 Conv20 층이 출력한 특성 맵\n",
        "\n",
        "첫 번째 층의 출력은 Conv2D 객체의 output 속성에서 얻을 수 있음\n",
        "\n",
        "이것은 modellayers[o.output 처럼 참조 가능\n",
        "\n",
        "model 객체의 입력은 input 속성으로 알 수 있음 (케라스 모델은 input 속성으로 입력을 참조할 수 있음)"
      ],
      "metadata": {
        "id": "hR_-fknplNxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conv_acti = keras.Model(model.input, model.layers[0].output)"
      ],
      "metadata": {
        "id": "LWhsY2f-kiiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "F7p7MgWUliEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(train_input[0], cmap='gray_r')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1lx4vxuSlkcy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "앵클 부츠\n",
        "\n",
        "이 샘플을 conv_acti 모델에 주입하여 Conv2D 층이 만드는 특성 맵을 출력해보자"
      ],
      "metadata": {
        "id": "svDYOTZAllRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = train_input[0:1].reshape(-1, 28, 28, 1)/255.0\n",
        "feature_maps = conv_acti.predict(inputs)\n",
        "print(feature_maps.shape)"
      ],
      "metadata": {
        "id": "tDIbuPFTlvqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(4, 8, figsize=(15,8))\n",
        "\n",
        "for i in range(4):\n",
        "    for j in range(8):\n",
        "        axs[i, j].imshow(feature_maps[0,:,:,i*8 + j])\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KAb9N9iYmZ0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv2_acti = keras.Model(model.input, model.layers[2].output)"
      ],
      "metadata": {
        "id": "nVhhs6TWnXdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_maps = conv2_acti.predict(train_input[0:1].reshape(-1, 28, 28, 1)/255.0)"
      ],
      "metadata": {
        "id": "MTT0b-YLnYPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_maps.shape)"
      ],
      "metadata": {
        "id": "EWNgbHaZnZEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "32개의 필터로 인해 입력 이미지에서 강하게 활성화된 부분을 보여주며, 비교를 위해 필터를 다시 출력함\n",
        "\n",
        "첫 번째 줄의 7번째 그리고 네 번째 줄의 4번째 필터들은 전체적으로 밝은색이므로 전면이 모두 칠해진 영역을 감지함 반대로 두 번째 줄의 6번재 필터는 전체적으로 낮은 음수 값이며, 이 필터와 큰 양수가 곱해지면 더 큰 음수가 되고 배경처럼 0에 가까은 값과 곱해 지면 작은 음수가 됨\n",
        "\n",
        "즉 부츠의 배경이 상대적으로 크게 활성화될 수 있음\n",
        "\n",
        "첫 번째 줄의 8번재 필터는 오른쪽의 수직선을 감지하므로 이 필터가 감지한 수직선이 강하게 활성화되어있음\n",
        "\n",
        "두 번째 합성곱 층의 특성 맵 확인\n",
        "\n",
        "입력층 부터 시작하여 첫 번째 합성곱 층, 첫 번째 맥스폴링 층, 두 번째 합성곱 층을 통과함"
      ],
      "metadata": {
        "id": "m4NcTrTgnaUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(8, 8, figsize=(12,12))\n",
        "\n",
        "for i in range(8):\n",
        "    for j in range(8):\n",
        "        axs[i, j].imshow(feature_maps[0,:,:,i*8 + j])\n",
        "        axs[i, j].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rbTaMis0nbYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "시각적으로 이해하기 힘듦 두 번째 합성곱 층의 필터 크기는 (3;3,32)\n",
        "\n",
        "두 번째 합성곱 층의 첫 번째 필터가 앞서 출력한 32개의 특성 맵과 곱해져 두 번째 합성곱 층의 첫 번째 특성 맵이 됨\n",
        "\n",
        "이렇게 계산된 출력은 (14,14,32) 특성 맵에서 어떤 부위를 감지하는지 직관적으로 이해하기 어려움 이러한 현상은 합성곱 층을 많이 쌓을수록 심해짐\n",
        "\n",
        "이를 바꾸어 생각하면 합성곱 신경망의 앞부분에 있는 합성곱 층은 이미지의 시각적인 정보를 감지하고 뒤쪽에 있는 합성곱 층은 앞쪽에서 감지한 시각적인 정보를 바탕으로 추상적인 정보를 학습한다고 볼 수 있음\n",
        "\n",
        "이것이 합성곱 신경망이 패션 MNIST 이미지를 인식하여 10개의 클래스를 찾아낼 수 있는 이유임"
      ],
      "metadata": {
        "id": "RvHBk-18ndGF"
      }
    }
  ]
}